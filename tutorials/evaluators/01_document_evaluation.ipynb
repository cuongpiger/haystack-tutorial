{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DocumentMAPEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuongdm/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from haystack.components.evaluators import DocumentMAPEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = DocumentMAPEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluator.run(\n",
    "    ground_truth_documents=[\n",
    "        [Document(content=\"France\")],\n",
    "        [Document(content=\"9th century\"), Document(content=\"9th\")],\n",
    "    ],\n",
    "    retrieved_documents=[\n",
    "        [Document(content=\"France\")],\n",
    "        [\n",
    "            Document(content=\"9th century\"),\n",
    "            Document(content=\"10th century\"),\n",
    "            Document(content=\"9th\"),\n",
    "        ],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9166666666666666, 'individual_scores': [1.0, 0.8333333333333333]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `RagasEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.ragas import (\n",
    "    RagasEvaluator,\n",
    "    RagasMetric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_pipeline = Pipeline()\n",
    "evaluator_context = RagasEvaluator(\n",
    "    metric=RagasMetric.CONTEXT_PRECISION,\n",
    ")\n",
    "evaluator_aspect = RagasEvaluator(\n",
    "    metric=RagasMetric.ASPECT_CRITIQUE,\n",
    "    metric_params={\n",
    "        \"name\": \"custom\",\n",
    "        \"definition\": \"Is this answer problematic for children?\",\n",
    "        \"strictness\": 3,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_pipeline.add_component(\"evaluator_context\", evaluator_context)\n",
    "evaluation_pipeline.add_component(\"evaluator_aspect\", evaluator_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.07433333333333333, 'rouge2': 0.02, 'rougeL': 0.07544444444444445, 'rougeLsum': 0.07388888888888889}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "# Load model and tokenizer\n",
    "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"squad\", split=\"validation[:100]\")\n",
    "\n",
    "# Prepare evaluation\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Generate predictions\n",
    "references = [item[\"answers\"][\"text\"][0] for item in dataset]\n",
    "predictions = [generator(item[\"question\"])[0][\"generated_text\"] for item in dataset]\n",
    "\n",
    "# Compute Rouge\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
