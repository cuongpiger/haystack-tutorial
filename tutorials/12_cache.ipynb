{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache\n",
    "\n",
    "Run Postgre Database in a Docker container:\n",
    "  ```bash\n",
    "  docker run -d -p 5432:5432 -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=postgres ankane/pgvector\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.caching import CacheChecker\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_doc_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For URL-based caching\n",
    "cache_checker = CacheChecker(document_store=my_doc_store, cache_field=\"url\")\n",
    "cache_check_results = cache_checker.run(items=[\"https://example.com/resource\", \"https://another_example.com/other_resources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['https://example.com/resource', 'https://another_example.com/other_resources']\n"
     ]
    }
   ],
   "source": [
    "print(cache_check_results[\"hits\"])    # List of Documents that were found in the cache: all of these have 'url': <one of the above> in the metadata\n",
    "print(cache_check_results[\"misses\"])  # URLs that were not found in the cache, like [\"https://example.com/resource\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For caching based on a custom identifier\n",
    "cache_checker = CacheChecker(document_store=my_doc_store, cache_field=\"metadata_field\")\n",
    "cache_check_results = cache_checker.run(items=[\"12345\", \"ABCDE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['12345', 'ABCDE']\n"
     ]
    }
   ],
   "source": [
    "print(cache_check_results[\"hits\"])    # Documents that were found in the cache: all of these have 'metadata_field': <one of the above> in the metadata\n",
    "print(cache_check_results[\"misses\"])  # Values that were not found in the cache, like: [\"ABCDE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.caching import CacheChecker\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7bc0aff3ef90>\n",
       "ðŸš… Components\n",
       "  - cache_checker: CacheChecker\n",
       "  - text_file_converter: TextFileToDocument\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - cache_checker.misses -> text_file_converter.sources (List)\n",
       "  - text_file_converter.documents -> cleaner.documents (List[Document])\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "pipeline.add_component(instance=CacheChecker(document_store, cache_field=\"file_path\"), name=\"cache_checker\")\n",
    "pipeline.add_component(instance=TextFileToDocument(), name=\"text_file_converter\")\n",
    "pipeline.add_component(instance=DocumentCleaner(), name=\"cleaner\")\n",
    "pipeline.add_component(instance=DocumentSplitter(split_by=\"sentence\", split_length=250, split_overlap=30), name=\"splitter\")\n",
    "pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"writer\")\n",
    "\n",
    "pipeline.connect(\"cache_checker.misses\", \"text_file_converter.sources\")\n",
    "pipeline.connect(\"text_file_converter.documents\", \"cleaner.documents\")\n",
    "pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
    "pipeline.connect(\"splitter.documents\", \"writer.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"pipeline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache_checker': {'hits': []}, 'writer': {'documents_written': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Take the current directory as input and run the pipeline\n",
    "result = pipeline.run({\"cache_checker\": {\"items\": [\"code_of_conduct_1.txt\"]}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cache_checker': {'hits': [Document(id=090bc39394bb7294026a00230d15a9da39d9eb432a65fe6134bad58a96389109, content: 'My name is Cuong, I am a software engineer.', meta: {'file_path': 'code_of_conduct_1.txt', 'source_id': '8a71ffffa4d1c4114c5cd8e459f1d7bf193440d187dccd80f2d1de3c74112677', 'page_number': 1, 'split_id': 0, 'split_idx_start': 0, '_split_overlap': []})]}, 'writer': {'documents_written': 0}}\n"
     ]
    }
   ],
   "source": [
    "# The second execution skips the files that were already processed\n",
    "result = pipeline.run({\"cache_checker\": {\"items\": [\"code_of_conduct_1.txt\"]}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
